{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9139ea5f-4273-4845-922a-f8dc9afb2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images to be downloaded: 20\n",
      "Downloaded image 1\n",
      "Downloaded image 2\n",
      "Downloaded image 3\n",
      "Downloaded image 4\n",
      "Downloaded image 5\n",
      "Downloaded image 6\n",
      "Downloaded image 7\n",
      "Downloaded image 8\n",
      "Downloaded image 9\n",
      "Downloaded image 10\n",
      "Downloaded image 11\n",
      "Downloaded image 12\n",
      "Downloaded image 13\n",
      "Downloaded image 14\n",
      "Downloaded image 15\n",
      "Downloaded image 16\n",
      "Downloaded image 17\n",
      "Downloaded image 18\n",
      "Downloaded image 19\n",
      "Downloaded image 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import httpx\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "def fetch_image_data(keyword, per_page, num_pages):\n",
    "    all_results = []\n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = f\"https://unsplash.com/napi/search/photos?page={page}&per_page={per_page}&query={keyword}?license=free\" #license = free necessary for cc images\n",
    "        response = httpx.get(url)\n",
    "        if response.status_code == 200:\n",
    "            all_results.extend(response.json().get('results', []))\n",
    "        else:\n",
    "            print(f\"Error: Status code {response.status_code} for page {page}\")\n",
    "            break\n",
    "    return all_results\n",
    "\n",
    "def extract_image_urls(data):\n",
    "    urls = []\n",
    "    for item in data:\n",
    "        raw_url = item['urls']['raw']\n",
    "        urls.append(raw_url.split('?')[0]) # Removing query parameters\n",
    "    return urls\n",
    "\n",
    "def download_images(urls, directory=\"images\"):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for idx, url in enumerate(urls, start=1):\n",
    "        try:\n",
    "            image_data = httpx.get(url).content\n",
    "            with open(os.path.join(directory, f\"image{idx}.jpg\"), 'wb') as file:\n",
    "                file.write(image_data)\n",
    "            print(f\"Downloaded image {idx}\")\n",
    "        except:\n",
    "            print(f\"Can't download image {idx}, continuing on\")\n",
    "\n",
    "keyword = \"mountains\"\n",
    "num_pages = 1  #Number of pages you want to fetch\n",
    "per_page = 10  #Number of images per page\n",
    "all_images = fetch_image_data(keyword, per_page, num_pages)\n",
    "\n",
    "if all_images:  #Ensure there are results\n",
    "    urls = extract_image_urls(all_images)  #Extract URLs\n",
    "    print(f\"Total images to be downloaded: {len(urls)}\")\n",
    "    download_images(urls, directory=\"mountain_range_photos\")\n",
    "else:\n",
    "    print(\"No results found, or an error occured.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmp_gdal_conda",
   "language": "python",
   "name": "mmp_gdal_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
